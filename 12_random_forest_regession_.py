# -*- coding: utf-8 -*-
"""12.Random Forest Regession .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hFFhuGsloE1KmefKQhLZY1qJK8yn141_

# BUSINESS PROBLEM- Predict the price of Banglore House

## Random Forest Regession - Supervised Machine Learning Algorithms

What is Random Forest?

What is Random Forest used for?

How do Random Forest work?

What is Random Forest Regression?
    
    A random forest is a meta estimator that fits a number of classifying
    decision trees on various sub-samples of the dataset and uses averaging
    to improve the predictive accuracy and control over-fitting.

What is Gini impurity, entropy, cost function for CART algorithm?

What is Random Forest diagram?

What is the difference between decision tree and random forest?

How to implement Random Forest Regression in python using sklearn?

### Import Library
"""

import pandas as pd
import numpy as np

"""0. NOTES FOr LOAD Data from Googe Drive
1. "https://drive.google.com/file/d/1zFfeKHIPo5i8kj-KOIuMIa-ANakxCeAN/view?usp=sharing"   -->Orignl Data
2. id=1zFfeKHIPo5i8kj-KOIuMIa-ANakxCeAN ----->this we get from orignal link this it is present b/w (/d/********/view?)

3. https://drive.google.com/uc?export=download&id=  ===>>At id=(we place the id 
of orignal link)
"""

# https://drive.google.com/file/d/115CTA-tBV8a_VFYzUCk_MkaAJIq4xBAt/view?usp=sharing

path=r"https://drive.google.com/uc?export=download&id=115CTA-tBV8a_VFYzUCk_MkaAJIq4xBAt"
df=pd.read_csv(path)

df.head()

"""## Split Data"""

X=df.drop('price',axis=1)    #Independent variable
y=df['price']                # Dependent variable

print("Shape of x=",X.shape)   #107 features or columns
print("Shape of y=",y.shape)   # only one feature price

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=51)   # Test percentage data=20 AND Remaining are train data

print("Shape of x_train=",X_train.shape)
print("Shape of x_test=",X_test.shape)   
print("Shape of y_train=",y_train.shape)
print("Shape of y_test=",y_test.shape)

"""##### Feature Scaling

## Random Forest Regession - ML_Model training
"""

from sklearn.ensemble import RandomForestRegressor

regressor =RandomForestRegressor(n_estimators=100,criterion='mse')

""" ## parameter OF RandomForestRegressor() 

    RandomForestRegressor(n_estimators=100, *, criterion="squared_error", max_depth=None, 
    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0, max_features="auto",
    max_leaf_nodes=None, min_impurity_decrease=0, bootstrap=True, oob_score=False, n_jobs=None, 
    random_state=None, verbose=0,warm_start=False, ccp_alpha=0, max_samples=None) -> None
  
  #### Parameter in Details:-
    1.n_estimators : int, default=100 => The number of trees in the forest.
    2.criterion : {"squared_error", "absolute_error", "poisson"},  default="squared_error"}
  
    n_estimators : The function to measure the quality of a split. Supported criteria are "squared_error" for the mean squared error, which is equal to
    variance reduction as feature selection criterion, "absolute_error"
    for the mean absolute error, and "poisson" which uses reduction in
    Poisson deviance to find splits.
"""

# Train the  model                  
regressor.fit(X_train,y_train)

# Accuracy or Score=98% very Good

regressor.score(X_test,y_test)

# bY tAKING  n_estimators=300
regressor_300 =RandomForestRegressor(n_estimators=300,criterion='mse')   
# Train the  model                  
regressor_300.fit(X_train,y_train)
# Accuracy gets Incresed
regressor_300.score(X_test,y_test)

"""## Predict House price"""

X_test.iloc[-1, :]     # Return the LAst Home ANd all Its Features

# Price Of Last Home is 81 lakh
regressor.predict([X_test.iloc[-1,:]])

# Orignal Price OF House Its Prediction is almost same
y_test.iloc[-1]

# Price Prediction OF Multiple House
pred=regressor.predict(X_test)
pred

#Orignal Price of House
y_test

"""NOW Compare The Acuracy of House Price Prediction Of Random Forest Regression And Decision  Treee Regression
     
    random Forest prediction is good as compare to Decision Tree
"""